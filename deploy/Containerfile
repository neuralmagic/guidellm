ARG BASE_IMAGE=docker.io/python:3.13-slim

# Use a multi-stage build to create a lightweight production image
FROM $BASE_IMAGE as builder

# Ensure files are installed as root
USER root

# Copy repository files
COPY / /opt/app-root/src

# Create a venv and install guidellm
RUN python3 -m venv /opt/app-root/guidellm \
    && /opt/app-root/guidellm/bin/pip install --no-cache-dir /opt/app-root/src

# Prod image
FROM $BASE_IMAGE

# Copy the virtual environment from the builder stage
COPY --from=builder /opt/app-root/guidellm /opt/app-root/guidellm

# Add guidellm bin to PATH
ENV PATH="/opt/app-root/guidellm/bin:$PATH"

# Create a non-root user
RUN useradd -md /results guidellm

# Switch to non-root user
USER guidellm

# Set working directory
WORKDIR /results

# Metadata
LABEL org.opencontainers.image.source="https://github.com/vllm-project/guidellm" \
      org.opencontainers.image.description="GuideLLM Performance Benchmarking Container"

# Set the environment variable for the benchmark script
# TODO: Replace with scenario environment variables
ENV GUIDELLM_TARGET="http://localhost:8000" \
    GUIDELLM_MODEL="neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w4a16" \
    GUIDELLM_RATE_TYPE="sweep" \
    GUIDELLM_DATA="prompt_tokens=256,output_tokens=128" \
    GUIDELLM_MAX_REQUESTS="100" \
    GUIDELLM_MAX_SECONDS="" \
    GUIDELLM_OUTPUT_PATH="/results/results.json"

ENTRYPOINT [ "/opt/app-root/guidellm/bin/guidellm" ]
CMD [ "benchmark", "run" ]
