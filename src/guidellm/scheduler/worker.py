import asyncio
import math
import multiprocessing
import multiprocessing.queues
import time
from abc import ABC, abstractmethod
from dataclasses import dataclass
from typing import (
    Any,
    AsyncGenerator,
    Dict,
    Generic,
    Literal,
    Optional,
    Tuple,
    Union,
)

from loguru import logger
from pydantic import Field

from guidellm.backend import (
    Backend,
    BackendType,
    RequestArgs,
    ResponseSummary,
    StreamingTextResponse,
)
from guidellm.config import settings
from guidellm.objects import Serializable
from guidellm.request import GenerationRequest
from guidellm.scheduler.result import SchedulerRequestInfo
from guidellm.scheduler.types import REQ, RES

__all__ = [
    "WorkerProcessRequest",
    "WorkerProcessResult",
    "RequestsWorker",
    "GenerativeRequestsWorker",
]


@dataclass
class WorkerProcessRequest(Generic[REQ]):
    request: REQ
    start_time: float
    timeout_time: Optional[float]
    queued_time: float


@dataclass
class WorkerProcessResult(Generic[REQ, RES]):
    type_: Literal["request_scheduled", "request_start", "request_complete"]
    request: REQ
    response: RES
    info: SchedulerRequestInfo


class RequestsWorker(ABC, Generic[REQ, RES]):
    """
    An abstract base class for a worker that processes requests.
    This class defines the interface for a worker that can resolve requests
    asynchronously or synchronously within the Scheduler class.
    Subclasses must implement the `resolve` method,
    which takes a request directly given from the load generator,
    along with the desired start_time for the request and a timeout_time.
    The `resolve` method should return the response from the backend.
    """

    @property
    @abstractmethod
    def description(self) -> Serializable:
        """
        An abstract property that must be implemented by subclasses.
        This property should return a Serializable class representing the information
        about the worker instance.
        """
        ...

    @abstractmethod
    async def resolve(
        self,
        request: REQ,
        timeout_time: float,
    ) -> RES:
        """
        An abstract method that must be implemented by subclasses.
        This method should handle the resolution of a request through asyncio,
        including any necessary backend processing and response handling.

        :param request: The request to be resolved generated by the load generator.
        :param timeout_time: The timeout time for the request, if there is no timeout
            given, then this will be math.inf.
        :return: The response from the worker.
        """
        ...

    async def resolve_scheduler_request(
        self,
        request: Any,
        queued_time: float,
        start_time: float,
        timeout_time: float,
        results_queue: multiprocessing.Queue,
        process_id: int,
    ):
        info = SchedulerRequestInfo(
            targeted_start_time=start_time,
            queued_time=queued_time,
            scheduled_time=time.time(),
            worker_start=-1,
            worker_end=-1,
            process_id=process_id,
        )
        result: WorkerProcessResult[REQ, RES] = WorkerProcessResult(
            type_="request_scheduled",
            request=request,
            response=None,
            info=info,
        )
        results_queue.put(result)

        if (wait_time := start_time - time.time()) > 0:
            await asyncio.sleep(wait_time)

        info.worker_start = time.time()
        result = WorkerProcessResult(
            type_="request_start",
            request=request,
            response=None,
            info=info,
        )
        results_queue.put(result)

        response = await self.resolve(request, timeout_time)

        info.worker_end = time.time()
        result = WorkerProcessResult(
            type_="request_complete",
            request=request,
            response=response,
            info=info,
        )
        results_queue.put(result)

    def process_loop_synchronous(
        self,
        requests_queue: multiprocessing.Queue,
        results_queue: multiprocessing.Queue,
        process_id: int,
    ):
        async def _process_runner():
            while True:
                try:
                    process_request: Optional[WorkerProcessRequest[REQ]] = (
                        requests_queue.get_nowait()
                    )
                except multiprocessing.queues.Empty:
                    # yield control to the event loop
                    await asyncio.sleep(settings.default_async_loop_sleep)
                    continue

                if process_request is None:  # stop signal
                    break

                await self.resolve_scheduler_request(
                    request=process_request.request,
                    queued_time=process_request.queued_time,
                    start_time=process_request.start_time,
                    timeout_time=process_request.timeout_time,
                    results_queue=results_queue,
                    process_id=process_id,
                )

        try:
            asyncio.run(_process_runner())
        except Exception as exc:  # noqa: BLE001
            logger.error(
                f"Error in worker process {process_id}: {exc}",
                exc_info=True,
                stack_info=True,
            )

    def process_loop_asynchronous(
        self,
        requests_queue: multiprocessing.Queue,
        results_queue: multiprocessing.Queue,
        max_concurrency: Optional[int],
        process_id: int,
    ):
        async def _process_runner():
            pending = asyncio.Semaphore(max_concurrency) if max_concurrency else None

            while True:
                try:
                    process_request: Optional[WorkerProcessRequest[REQ]] = (
                        requests_queue.get_nowait()
                    )
                except multiprocessing.queues.Empty:
                    # yield control to event loop
                    await asyncio.sleep(settings.default_async_loop_sleep)
                    continue

                if process_request is None:  # stop signal
                    break

                if pending:
                    await pending.acquire()

                def _task_done(_: asyncio.Task):
                    nonlocal pending
                    if pending:
                        pending.release()

                task = asyncio.create_task(
                    self.resolve_scheduler_request(
                        request=process_request.request,
                        queued_time=process_request.queued_time,
                        start_time=process_request.start_time,
                        timeout_time=process_request.timeout_time,
                        results_queue=results_queue,
                        process_id=process_id,
                    )
                )
                task.add_done_callback(_task_done)
                await asyncio.sleep(0)  # enable start task immediately

        try:
            asyncio.run(_process_runner())
        except Exception as exc:  # noqa: BLE001
            logger.error(
                f"Error in worker process {process_id}: {exc}",
                exc_info=True,
                stack_info=True,
            )


class GenerativeRequestsWorkerDescription(Serializable):
    backend_type: BackendType
    backend_target: str
    backend_model: str
    backend_info: Dict[str, Any] = Field(
        default_factory=dict,
    )


class GenerativeRequestsWorker(RequestsWorker[GenerationRequest, ResponseSummary]):
    """
    A class that handles the execution of requests using a backend.
    This class is responsible for sending requests to the backend,
    handling responses, and managing errors.

    :param backend: The backend to use for handling requests.
        This should be an instance of Backend such as an OpenAIHTTPBackend.
    """

    def __init__(self, backend: Backend):
        self.backend = backend

    @property
    def description(self) -> Serializable:
        """
        Get the description of the worker.
        :return: The description of the worker.
        """
        return GenerativeRequestsWorkerDescription(
            backend_type=self.backend.type_,
            backend_target=self.backend.target,
            backend_model=self.backend.model,
            backend_info=self.backend.info,
        )

    async def resolve(
        self,
        request: GenerationRequest,
        timeout_time: float,
    ) -> ResponseSummary:
        """
        Resolve a request by sending it to the backend and handling the response.
        This method sends the request to the backend, waits for a response,
        and handles any errors that may occur during the process.

        :param request: The request to resolve.
        :param timeout_time: The time to wait for a response before timing out.
            If timeout_time is math.inf, the request will not timeout.
        :return: A ResponseSummary object containing the response from the backend.
            If an error occurs, the ResponseSummary will contain the error message.
        """
        response = None
        error: Optional[str] = None

        try:
            request_func, request_kwargs = self._create_request_func_kwargs(request)

            async def _runner():
                # wrap function so we can enforce timeout and
                # still return the latest state from the backend
                async for resp in request_func(**request_kwargs):
                    nonlocal response
                    response = resp

            await asyncio.wait_for(
                _runner(),
                timeout=timeout_time - time.time() if timeout_time < math.inf else None,
            )

            if not response:
                raise ValueError(
                    f"No response received for request: {request} "
                    f"and backend: {self.backend}"
                )
            if not isinstance(response, ResponseSummary):
                raise ValueError(
                    f"Received no ResponseSummary for request: {request} "
                    f"and backend: {self.backend}, received: {response}"
                )
        except asyncio.TimeoutError as texc:
            error = str(texc)
        except Exception as exc:  # noqa: BLE001
            error = str(exc)

        return self._handle_response(request, response, error)

    def _create_request_func_kwargs(
        self,
        request: GenerationRequest,
    ) -> Tuple[
        AsyncGenerator[Union[StreamingTextResponse, ResponseSummary], None],
        Dict[str, Any],
    ]:
        request_func: AsyncGenerator[
            Union[StreamingTextResponse, ResponseSummary], None
        ]
        request_kwargs: Dict[str, Any]

        if request.request_type == "text_completions":
            request_func = self.backend.text_completions
            request_kwargs = {
                "prompt": request.content,
                "request_id": request.request_id,
                "prompt_token_count": request.stats.get("prompt_tokens", None),
                "output_token_count": request.constraints.get("output_tokens", None),
                **request.params,
            }
        elif request.request_type == "chat_completions":
            request_func = self.backend.chat_completions
            request_kwargs = {
                "content": request.content,
                "request_id": request.request_id,
                "prompt_token_count": request.stats.get("prompt_tokens", None),
                "output_token_count": request.constraints.get("output_tokens", None),
                **request.params,
            }
        else:
            raise ValueError(
                f"Invalid request type: {request.request_type} for {request}"
            )

        return request_func, request_kwargs

    def _handle_response(
        self,
        request: GenerationRequest,
        response: Any,
        error: Optional[str],
    ) -> ResponseSummary:
        if response is None or not isinstance(
            response, (ResponseSummary, StreamingTextResponse)
        ):
            # nothing received or invalid response, fill in defaults for error
            if response:
                error = str(
                    ValueError(
                        f"Invalid response: {type(response)} for request: {request}; "
                    )
                ) + (error or "")

            return ResponseSummary(
                value="",
                request_args=RequestArgs(
                    target=self.backend.target,
                    headers={},
                    payload={},
                ),
                start_time=None,
                end_time=None,
                request_id=request.request_id,
                error=error or "Unknown error",
            )

        if isinstance(response, StreamingTextResponse):
            return ResponseSummary(
                value=response.value,
                request_args=RequestArgs(
                    target=self.backend.target,
                    headers={},
                    payload={},
                ),
                start_time=response.start_time,
                end_time=None,
                request_prompt_tokens=request.stats.get("prompt_tokens", None),
                request_output_tokens=None,
                response_prompt_tokens=None,
                response_output_tokens=response.iter_count,
                request_id=request.request_id,
                error=error or "Unknown error",
            )

        response.error = error

        return response
