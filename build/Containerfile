ARG PYTHON=3.13

# Use a multi-stage build to create a lightweight production image
FROM docker.io/python:${PYTHON}-slim as builder

# Copy repository files
COPY / /src

# Create a venv and install guidellm
RUN python3 -m venv /opt/guidellm \
    && /opt/guidellm/bin/pip install --no-cache-dir /src

# Copy entrypoint script into the venv bin directory
RUN install -m0755 /src/build/entrypoint.sh /opt/guidellm/bin/entrypoint.sh

# Prod image
FROM docker.io/python:${PYTHON}-slim

# Copy the virtual environment from the builder stage
COPY --from=builder /opt/guidellm /opt/guidellm

# Add guidellm bin to PATH
ENV PATH="/opt/guidellm/bin:$PATH"

# Create a non-root user
RUN useradd -md /results guidellm

# Switch to non-root user
USER guidellm

# Set working directory
WORKDIR /results

# Metadata
LABEL org.opencontainers.image.source="https://github.com/neuralmagic/guidellm"
LABEL org.opencontainers.image.description="GuideLLM Benchmark Container"

# Set the environment variable for the benchmark script
# TODO: Replace with scenario environment variables
ENV TARGET="http://localhost:8000" \
    MODEL="neuralmagic/Meta-Llama-3.1-8B-Instruct-quantized.w4a16" \
    RATE_TYPE="sweep" \
    DATA="prompt_tokens=256,output_tokens=128" \
    MAX_REQUESTS="100" \
    MAX_SECONDS="" \
    OUTPUT_PATH="/results/results.json"

ENTRYPOINT [ "/opt/guidellm/bin/entrypoint.sh" ]
